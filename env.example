# MCP Codebase Analyser Configuration

# Server Configuration
HOST=0.0.0.0
PORT=8050
TRANSPORT=sse

# LLM Configuration
LLM_PROVIDER=openai
LLM_API_KEY=your_api_key_here
LLM_MODEL=gpt-4o-mini
LLM_BASE_URL=

# Embedding Configuration
EMBEDDING_MODEL=text-embedding-3-small

# GitHub Configuration (Optional - for private repos and better rate limits)
GITHUB_TOKEN=

# Storage Configuration
REPO_CACHE_DIR=./repo_cache
CHROMA_PERSIST_DIR=./chroma_db

# Parser Configuration
MAX_FILE_SIZE_KB=500
SUPPORTED_EXTENSIONS=.js,.jsx,.ts,.tsx

